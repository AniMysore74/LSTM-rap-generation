{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lyric generation with LSTMs\n",
    "\n",
    "**Author : ** Aniruddha Mysore\n",
    "\n",
    "Lyric data has been parsed from Lyrics Wikia. The songlist was parsed manually with beautiful soup, and used the API to get lyrics of each song - [API](https://github.com/rhnvrm/lyric-api)\n",
    "\n",
    "**Credits: **\n",
    " \n",
    "1. Videos on LSTMs and RNNs by Siraj Raval (Youtube)\n",
    "\n",
    "2. Ivan Liljeqvist's [article](https://medium.com/@ivanliljeqvist/using-ai-to-generate-lyrics-5aba7950903) on using Keras for generating lyrics and his [code](https://github.com/ivan-liljeqvist/ailyrics/) \n",
    "\n",
    "![](https://data.whicdn.com/images/36141347/large.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First: Data Collection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/wiki/Eminem:Infinite</td>\n",
       "      <td>Infinite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/wiki/Eminem:W.E.G.O.</td>\n",
       "      <td>W.E.G.O.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/wiki/Eminem:It%27s_OK</td>\n",
       "      <td>It%27s_OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/wiki/Eminem:313</td>\n",
       "      <td>313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/wiki/Eminem:Tonite</td>\n",
       "      <td>Tonite</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      url       name\n",
       "0   /wiki/Eminem:Infinite   Infinite\n",
       "1   /wiki/Eminem:W.E.G.O.   W.E.G.O.\n",
       "2  /wiki/Eminem:It%27s_OK  It%27s_OK\n",
       "3        /wiki/Eminem:313        313\n",
       "4     /wiki/Eminem:Tonite     Tonite"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "from urllib.request import urlopen\n",
    "import urllib.request\n",
    "import re \n",
    "\n",
    "# Get html\n",
    "url = 'http://lyrics.wikia.com/wiki/Eminem'\n",
    "r = requests.get(url)\n",
    "soup = BeautifulSoup(r.text, 'lxml')\n",
    "\n",
    "count = 0\n",
    "data = list()\n",
    "\n",
    "# Parse the data to get list of songs and urls\n",
    "for album in soup.find_all(class_='album-art'):\n",
    "    count += 1\n",
    "    for song in album.find_next('ol').children:\n",
    "        a = re.search('\\:(.*)', song.b.a['href'])\n",
    "        data.append({\n",
    "            'url': song.b.a['href'],\n",
    "            'name': a.group(1)\n",
    "        #    'name': song.b.a.contents[0]\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(data, columns=[\"url\",\"name\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spoken:\n",
      "Oh yeah, this is Eminem baby, back up in that motherfucking ass\n",
      "One time for your mother fucking mind, we represent the 313\n",
      "You know what I'm saying?, 'cause they don't know shit about this\n",
      "For the 9-6\n",
      "\n",
      "Ayo, my pen and paper cause a chain reaction\n",
      "To get your brain relaxin, 'cause they be actin' maniac in action\n",
      "A brainiac in fact son, you mainly lack attraction\n",
      "You looking zany whack with just a fraction of my tracks spun\n",
      "My rhyming skills got you climbing hills\n",
      "I travel through your mind into your spine like siren drills\n",
      "I'm sliming grills of roaches, with sprayed on disinfectants\n",
      "Twistin necks of rappers till their spinal column disconnects\n",
      "Put this in decks and check the monologue, turn your system up\n",
      "Twist them up, and indulge in the marijuana smog\n",
      "This is the season for noise pollution contamination\n",
      "Examination of more cartoons than animation\n",
      "My lamination of narration\n",
      "Hit's a snare and bass in the track fucked up rapper interrogation\n",
      "When I declare invasion, there ain't no time to be staring, gazing\n",
      "I turn the stage into a barren wasteland...\n",
      "I'm Infinite\n",
      "\n",
      "You heard of hell well I was sent from it\n",
      "I went to it serving a sentence for murdering instruments\n",
      "Now I'm trying to repent from it\n",
      "But when I hear the beat I'm tempted to make another attempt at it...\n",
      "I'm Infinite\n",
      "\n",
      "Bust it, I let the beat commence so I can beat the sense in your elite defense\n",
      "I got some meat to mince, a crew to stomp and then two feet to rinse\n",
      "I greet the gents and ladies, I spoil all your fans\n",
      "I foil plans and leave fluids leaking like oil pans\n",
      "My coiled hands around this microphone are lethal\n",
      "One thought in my cerebral is deeper then a Jeep full of people\n",
      "MC's are feeble, I came to cause some pandemonium\n",
      "Battle a band of phony MC's and stand the lonely one\n",
      "Imitator, Intimidator, Stimulator, Simulator of data, Eliminator\n",
      "There's never been a greater since the burial of Jesus\n",
      "Fuck around and catch all of the venereal diseases\n",
      "My thesis will smash a stereo to pieces\n",
      "My accapella releases plastic masterpieces through telekinesis\n",
      "That eases you mentally, gently, sentimentally, instrumentally\n",
      "With entity, dementedly meant to be Infinite\n",
      "\n",
      "You heard of hell well I was sent from it\n",
      "I went to it serving a sentence for murdering instruments\n",
      "Now I'm trying to repent from it\n",
      "But when I hear the beat I'm tempted to make another attempt at it...\n",
      "I'm Infinite\n",
      "\n",
      "Man I got evidence I'm never dense and I been clever ever since\n",
      "My residence was hesitant to do some shit that represents the M-O\n",
      "So I'm assuming all responsibility\n",
      "Cause there's a monster will in me that always wants to kill MC's\n",
      "Mic messaler, slamming like a wrestler\n",
      "Here to make a mess of a lyric smuggling embezzler\n",
      "No one is speacialer, My skill is intergalactical\n",
      "I get cynical act a fool then I send a crew back to school\n",
      "I never packed a tool or acted cool, it wasn't practical\n",
      "I'd rather let a tactical, tactful, track tickle your fancy\n",
      "In fact I can't see, or can't imagine\n",
      "A man who ain't a lover of beats or a fan of scratching\n",
      "This is for my family, the kid who had a cameo on my last jam\n",
      "Plus the man who never had a plan B\n",
      "Be all you can be, cause once you make an instant hit\n",
      "I'm tensed a bit and tempted when I see the sins my friends commit...\n",
      "I'm Infinite\n",
      "\n",
      "You heard of hell well I was sent from it\n",
      "I went to it serving a sentence for murdering instruments\n",
      "Now I'm trying to repent from it\n",
      "But when I hear the beat I'm tempted to make another attempt at it...\n",
      "I'm Infinite\n",
      "You heard of hell well I was sent from it\n",
      "I went to it serving a sentence for murdering instruments\n",
      "Now I'm trying to repent from it\n",
      "But when I hear the beat I'm tempted to make another attempt at it...\n",
      "I'm Infinite\n"
     ]
    }
   ],
   "source": [
    "# here's what the lyrics look like\n",
    "data = json.load(urlopen('http://lyric-api.herokuapp.com/api/find/Eminem/'+df.iloc[0]['name']))\n",
    "print(data['lyric'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Infinite\n",
      "1 W.E.G.O.\n",
      "2 It%27s_OK\n",
      "3 313\n",
      "4 Tonite\n",
      "5 Maxine\n",
      "6 Open_Mic\n",
      "7 Never_2_Far\n",
      "8 Searchin%27\n",
      "9 Backstabber\n",
      "10 Jealousy_Woes_II\n",
      "11 Intro_(Slim_Shady)\n",
      "12 Low_Down_Dirty\n",
      "13 If_I_Had\n",
      "14 Just_Don%27t_Give_A_Fuck\n",
      "15 Mommy\n",
      "16 Just_The_Two_Of_Us\n",
      "17 No_One%27s_Iller_Than_Me\n",
      "18 Murder_Murder\n",
      "19 If_I_Had_(Radio_Edit)\n",
      "20 Just_Don%27t_Give_A_Fuck_(Radio_Edit)\n",
      "21 Public_Service_Announcement\n",
      "22 My_Name_Is\n",
      "23 Guilty_Conscience\n",
      "24 Brain_Damage\n",
      "25 Paul\n",
      "26 If_I_Had\n",
      "27 %2797_Bonnie_%26_Clyde\n",
      "28 Bitch\n",
      "29 Role_Model\n",
      "30 Lounge\n",
      "31 My_Fault\n",
      "32 Ken_Kaniff#As_heard_on_The_Slim_Shady_LP\n",
      "33 Cum_On_Everybody\n",
      "34 Rock_Bottom\n",
      "35 Just_Don%27t_Give_A_Fuck\n",
      "36 Soap\n",
      "37 As_The_World_Turns\n",
      "38 I%27m_Shady\n",
      "39 Bad_Meets_Evil\n",
      "40 Still_Don%27t_Give_A_Fuck\n",
      "41 Hazardous_Youth\n",
      "42 Get_You_Mad\n",
      "43 Greg\n",
      "44 Public_Service_Announcement_2000\n",
      "45 Kill_You\n",
      "46 Stan\n",
      "47 Paul\n",
      "48 Who_Knew\n",
      "49 Steve_Berman\n",
      "50 The_Way_I_Am\n",
      "51 The_Real_Slim_Shady\n",
      "52 Remember_Me%3F\n",
      "53 I%27m_Back\n",
      "54 Marshall_Mathers\n",
      "55 Ken_Kaniff#As_heard_on_The_Marshall_Mathers_LP\n",
      "56 Drug_Ballad\n",
      "57 Amityville\n",
      "58 Bitch_Please_II\n",
      "59 Kim\n",
      "60 Under_The_Influence\n",
      "61 Criminal\n",
      "62 The_Kids\n",
      "63 Fuck_You_(Lab_Rat_Remix)\n",
      "64 Dead_Wrong\n",
      "65 Off_The_Wall\n",
      "66 If_I_Get_Locked_Up_Tonight\n",
      "67 Stir_Crazy\n",
      "68 Tylenol_Island\n",
      "69 Hellbound\n",
      "70 Shit_On_You\n",
      "71 Rush_Ya_Clique\n",
      "72 It%27s_Murda_(Cable_Guy_Remix)\n",
      "73 Murder_Murder\n",
      "74 Thug_Luv\n",
      "75 Our_House\n",
      "76 The_Kids\n",
      "77 We_Shine\n",
      "78 Turn_Me_Loose\n",
      "79 Fucking_Crazy\n",
      "80 Forgot_About_Dre\n",
      "81 Green_And_Gold\n",
      "82 Nuttin%27_To_Do\n",
      "83 Watch_Dees\n",
      "84 3_Verses\n",
      "85 Scary_Movies\n",
      "86 Get_You_Mad\n",
      "87 Fuck_Off\n",
      "88 Hustlers_And_Hardcore\n",
      "89 The_Anthem\n",
      "90 Busa_Rhyme\n",
      "91 Flyest_Material\n",
      "92 My_Name_Is\n",
      "93 5_Star_Generals\n",
      "94 The_Showdown\n",
      "95 Curtains_Up\n",
      "96 White_America\n",
      "97 Business\n",
      "98 Cleanin%27_Out_My_Closet\n",
      "99 Square_Dance\n",
      "100 The_Kiss\n",
      "101 Soldier\n",
      "102 Say_Goodbye_Hollywood\n",
      "103 Drips\n",
      "104 Without_Me\n",
      "105 Paul\n",
      "106 Sing_For_The_Moment\n",
      "107 Superman\n",
      "108 Hailie%27s_Song\n",
      "109 Steve_Berman\n",
      "110 When_The_Music_Stops\n",
      "111 Say_What_You_Say\n",
      "112 %27Till_I_Collapse\n",
      "113 My_Dad%27s_Gone_Crazy\n",
      "114 Curtains_Close\n",
      "115 Monkey_See_Monkey_Do\n",
      "116 We_Are_Americans\n",
      "117 Love_You_More\n",
      "118 Can-I-Bitch\n",
      "119 Bully\n",
      "120 Come_On_In\n",
      "121 Hailie%27s_Revenge\n",
      "122 The_Kids\n",
      "123 Stimulate\n",
      "124 Explosion?action=edit&redlink=1\n",
      "125 The_Conspiracy_Freestyle\n",
      "126 Bump_Heads\n",
      "127 Lose_Yourself\n",
      "128 Cleanin%27_Out_My_Closet\n",
      "129 Cleanin%27_Out_My_Closet\n",
      "130 Real_911?action=edit&redlink=1\n",
      "131 Don%27t_Call_Me_Marshall?action=edit&redlink=1\n",
      "132 My_Name\n",
      "133 Go_To_Sleep\n",
      "134 Nigga\n",
      "135 Shady_Camp?action=edit&redlink=1\n",
      "136 Business\n",
      "137 Patiently_Waiting\n",
      "138 Victory?action=edit&redlink=1\n",
      "139 Back_Down_Royce?action=edit&redlink=1\n",
      "140 The_Sauce\n",
      "141 The_Boston_Bitch?action=edit&redlink=1\n",
      "142 Rap_Game\n",
      "143 Nail_in_the_Coffin?action=edit&redlink=1\n",
      "144 Don%27t_Push_Me\n",
      "145 Lose_Yourself\n",
      "146 Love_Me\n",
      "147 Slut_Phone_Call?action=edit&redlink=1\n",
      "148 Superman\n",
      "149 Renegade\n",
      "150 Parking_Lot_Flows?action=edit&redlink=1\n",
      "151 8_More_Miles?action=edit&redlink=1\n",
      "152 It%27s_Only_Fair_To_Warn\n",
      "153 Stimulate\n",
      "154 The_Cross?action=edit&redlink=1\n",
      "155 Hellbound\n",
      "156 Nuttin%27_To_Do\n",
      "157 She%27s_The_One\n",
      "158 Three_Six_Five\n",
      "159 Scary_Movies\n",
      "160 Rush_Ya_Clique\n",
      "161 Hustlers_And_Hardcore\n",
      "162 Rock_City\n",
      "163 Macosa\n",
      "164 Nuttin%27_To_Do\n",
      "165 Scary_Movies\n",
      "166 Curtains_Up\n",
      "167 Evil_Deeds\n",
      "168 Never_Enough\n",
      "169 Yellow_Brick_Road\n",
      "170 Like_Toy_Soldiers\n",
      "171 Mosh\n",
      "172 Puke\n",
      "173 My_1st_Single\n",
      "174 Paul\n",
      "175 Rain_Man\n",
      "176 Big_Weenie\n",
      "177 Em_Calls_Paul\n",
      "178 Just_Lose_It\n",
      "179 Ass_Like_That\n",
      "180 Spend_Some_Time\n",
      "181 Mockingbird\n",
      "182 Crazy_In_Love\n",
      "183 One_Shot_2_Shot\n",
      "184 Final_Thought\n",
      "ERROR : 185 Encore_/_Curtains_Down\n",
      "186 We_As_Americans\n",
      "187 Love_You_More\n",
      "188 Ricky_Ticky_Toc\n",
      "189 Wanksta\n",
      "190 Renegade\n",
      "191 The_Way_I_Am\n",
      "192 Freestyle_(Dissin%27_The_Source)\n",
      "193 One_Day_At_A_Time_(Em%27s_Version)\n",
      "194 Many_Men?action=edit&redlink=1\n",
      "195 Just_Lose_It_(Instrumental)\n",
      "196 Just_Lose_It\n",
      "197 Intro_(Curtain_Call)\n",
      "198 Fack\n",
      "199 The_Way_I_Am\n",
      "200 My_Name_Is\n",
      "201 Stan\n",
      "202 Lose_Yourself\n",
      "203 Shake_That\n",
      "204 Sing_For_The_Moment\n",
      "205 Without_Me\n",
      "206 Like_Toy_Soldiers\n",
      "207 The_Real_Slim_Shady\n",
      "208 Mockingbird\n",
      "209 Guilty_Conscience\n",
      "210 Cleanin%27_Out_My_Closet\n",
      "211 Just_Lose_It\n",
      "212 When_I%27m_Gone\n",
      "213 Stan_(Live)\n",
      "214 Dr._West_(Skit)\n",
      "215 3_A.M.\n",
      "216 My_Mom\n",
      "217 Insane\n",
      "218 Bagpipes_From_Baghdad\n",
      "219 Hello\n",
      "220 Tonya\n",
      "221 Same_Song_%26_Dance\n",
      "222 We_Made_You\n",
      "223 Medicine_Ball\n",
      "224 Paul\n",
      "225 Stay_Wide_Awake\n",
      "226 Old_Time%27s_Sake\n",
      "227 Must_Be_The_Ganja\n",
      "228 Mr._Mathers\n",
      "229 D%C3%A9j%C3%A0_Vu\n",
      "230 Beautiful\n",
      "231 Crack_A_Bottle\n",
      "232 Steve_Berman\n",
      "233 Underground\n",
      "234 My_Darling\n",
      "235 Careful_What_You_Wish_For\n",
      "236 We_Made_You\n",
      "237 Crack_A_Bottle\n",
      "238 Forever\n",
      "239 Hell_Breaks_Loose\n",
      "240 Buffalo_Bill\n",
      "241 Elevator\n",
      "242 Taking_My_Ball\n",
      "243 Music_Box\n",
      "244 Drop_The_Bomb_On_%27Em\n",
      "245 Cold_Wind_Blows\n",
      "246 Talkin%27_2_Myself\n",
      "247 On_Fire\n",
      "248 Won%27t_Back_Down\n",
      "249 W.T.P.\n",
      "250 Going_Through_Changes\n",
      "251 Not_Afraid\n",
      "252 Seduction\n",
      "253 No_Love\n",
      "254 Space_Bound\n",
      "255 Cinderella_Man\n",
      "256 25_To_Life\n",
      "257 So_Bad\n",
      "258 Almost_Famous\n",
      "259 Love_The_Way_You_Lie\n",
      "260 You%27re_Never_Over\n",
      "261 Untitled\n",
      "262 Ridaz\n",
      "263 Session_One\n",
      "264 Bad_Guy\n",
      "265 Parking_Lot\n",
      "266 Rhyme_Or_Reason\n",
      "267 So_Much_Better\n",
      "268 Survival\n",
      "269 Legacy\n",
      "270 Asshole\n",
      "271 Berzerk\n",
      "272 Rap_God\n",
      "273 Brainless\n",
      "274 Stronger_Than_I_Was\n",
      "275 The_Monster\n",
      "276 So_Far...\n",
      "277 Love_Game\n",
      "278 Headlights\n",
      "279 Evil_Twin\n",
      "280 Baby\n",
      "281 Desperation\n",
      "282 Groundhog_Day\n",
      "283 Beautiful_Pain\n",
      "284 Wicked_Ways\n",
      "285 Don%27t_Front\n",
      "286 Walk_On_Water\n",
      "287 Believe\n",
      "288 Chloraseptic\n",
      "289 Untouchable\n",
      "290 River\n",
      "291 Remind_Me_(Intro)\n",
      "292 Remind_Me\n",
      "293 Revival_(Interlude)\n",
      "294 Like_Home\n",
      "295 Bad_Husband\n",
      "296 Tragic_Endings\n",
      "297 Framed\n",
      "298 Nowhere_Fast\n",
      "299 Heat\n",
      "300 Offended\n",
      "301 Need_Me\n",
      "302 In_Your_Head\n",
      "303 Castle\n",
      "304 Arose\n"
     ]
    }
   ],
   "source": [
    "#Saving the corpus file for training the model\n",
    "\n",
    "corpus = \"\"\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    try:\n",
    "        data = json.load(urlopen('http://lyric-api.herokuapp.com/api/find/Eminem/'+row['name']))\n",
    "        corpus += \"\\n\" + data['lyric']\n",
    "    except urllib.error.HTTPError:\n",
    "        print(\"ERROR :\",index, row['name'])\n",
    "    else:\n",
    "        print(index, row['name'])\n",
    "\n",
    "with open(\"corpus.txt\", \"w\") as text_file:\n",
    "    text_file.write(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our corpus file saved, it's time for\n",
    "\n",
    "## Second: Training the Model\n",
    "\n",
    "Before training we define the length of each line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "PATH = \"corpus.txt\" \n",
    "sequence_length = 40\n",
    "step = 3\n",
    "\n",
    "\n",
    "text = []\n",
    "chars = []\n",
    "\n",
    "\n",
    "# get the lyrics corpus from the file\n",
    "with io.open(PATH, 'r', encoding='utf8') as f:\n",
    "    text = f.read().lower()\n",
    "    chars = sorted(list(set(text)))\n",
    "\n",
    "# sequences is input to nueral network\n",
    "# next_chars are labels while training\n",
    "sequences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - sequence_length, step):\n",
    "    sequences.append(text[i: i + sequence_length])\n",
    "    next_chars.append(text[i + sequence_length])\n",
    "\n",
    "    \n",
    "char_to_index = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization\n",
    "\n",
    "We need to convert all our character strings into a format that can be used by the LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# vectorize the data since we cannot use characters and strings \n",
    "\n",
    "X = np.zeros((len(sequences), sequence_length, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sequences), len(chars)), dtype=np.bool)\n",
    "\n",
    "for i, sentence in enumerate(sequences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i, t, char_to_index[char]] = 1\n",
    "        y[i, char_to_index[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "This may take some time to run. Be default the model trains for 20 epochs.\n",
    "\n",
    "On my NVIDIA 940MX laptop GPU, each epoch takes about 2 minutes 30 seconds\n",
    "\n",
    "You can skip the training by using the pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# MODEL TRAINING\n",
    "# skip this if you want to use the pretrained model\n",
    "\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "EPOCHS = 20\n",
    "\n",
    "# this is our keras model. It has 128 LSTM neurons\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(sequence_length, len(chars))))\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "\n",
    "#UNCOMMENT TO TRAIN : \n",
    "\n",
    "# model.fit(X, y, batch_size=128, nb_epoch=EPOCHS)\n",
    "# model.save('eminem.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# load pretrained\n",
    "\n",
    "model = load_model(\"eminem.h5\")  # you can skip training by loading the trained weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third: Predictions\n",
    "\n",
    "Now for the fun part :)\n",
    "\n",
    "The diversity parameter controls how similar each line of lyrics will be. The iteration explores lyrics at different values of Diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================\n",
      "DIVERSITY: 0.2\n",
      "SEED: \"i want to go back home tonight so i can \"\n",
      "====================================================\n",
      "i want to go back home tonight so i can started in a song and i can say\n",
      "\n",
      "i got the shit the way i was some shot of the michate off in the mind of the mind of the shit\n",
      "so destreminant to say the shit i can say the mind\n",
      "i say i got the morning of the bell and i can started to hear me\n",
      "the street and the belong of the shit i think i was somebody and we as i was a motherfuckin' that i got the morning and started in the mind of the bottom\n",
      "\n",
      "i \n",
      "\n",
      "====================================================\n",
      "DIVERSITY: 0.5\n",
      "SEED: \"i want to go back home tonight so i can \"\n",
      "====================================================\n",
      "i want to go back home tonight so i can say\n",
      "i hear me in the bone the reason i'm the thing to the really on the day\n",
      "i can be careed on shot it and you say the change to suck your show\n",
      "but i litter fine 'em back and things that you see it\n",
      "when i was surrous of who when i god i go to the one fuckin' when i don't got to pee some syult\n",
      "the michates!)\n",
      "i got up in the morning out and have it and it every, i wanna change to say\n",
      "be like her car\n",
      "\n",
      "====================================================\n",
      "DIVERSITY: 1.0\n",
      "SEED: \"i want to go back home tonight so i can \"\n",
      "====================================================\n",
      "i want to go back home tonight so i can only never cansinid chaning\n",
      "lonely bitch, a what up as you just grow me\n",
      "they cheeting\n",
      "ope in and stay so inside\n",
      "\n",
      "maybe amence-y-man, but i give a lit with my ass horb\n",
      "!j?\n",
      "\n",
      "fack, and how was someone gives me right\n",
      "i got the one slappers you and shone accust\n",
      "all niod\n",
      "and a girls of an astema coswor a fault andr\n",
      "who little out of just\n",
      "but  somed\n",
      "there is recisting with a opphice?\n",
      "yeah i want here -ay\n",
      "\n",
      "====================================================\n",
      "DIVERSITY: 1.2\n",
      "SEED: \"i want to go back home tonight so i can \"\n",
      "====================================================\n",
      "i want to go back home tonight so i can hizer to breeut\n",
      "carebuder ha) i can grow ativha ead\n",
      "passin' why i've wanna 'cause you dose\n",
      "juck you're aguight, murder my's bust and shut the candomm frog be face\n",
      "slim shady to do and shove her and glolks\n",
      "igsturse it's nothing on it\n",
      "\n",
      "told sarthes a invois in insawand knuckin' man\n",
      "you give i was tome!\"\n",
      "housassent over me -untoss)\n",
      "suck witucod?ng..., i think the wricks got to high aasy!\n",
      "\n",
      "(\") byvanc \n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "INPUT = \"i want to go back home tonight so I can \"\n",
    "\n",
    "if len(sentence) is not 40:\n",
    "    print(\"Sentence length is\", len(sentence))\n",
    "\n",
    "else:\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print()\n",
    "        print('====================================================\\nDIVERSITY:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        # insert your 40-chars long string. OBS it needs to be exactly 40 chars!\n",
    "        sentence = INPUT\n",
    "        sentence = sentence.lower()\n",
    "        generated += sentence\n",
    "\n",
    "        print('SEED: \"' + sentence + '\"\\n====================================================')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x = np.zeros((1, sequence_length, len(chars)))\n",
    "\n",
    "            for t, char in enumerate(sentence):\n",
    "                x[0, t, char_to_index[char]] = 1.\n",
    "\n",
    "\n",
    "            predictions = model.predict(x, verbose=0)[0]\n",
    "\n",
    "            if diversity == 0:\n",
    "                diversity = 1\n",
    "\n",
    "            preds = np.asarray(predictions).astype('float64')\n",
    "            preds = np.log(preds) / diversity\n",
    "            exp_preds = np.exp(preds)\n",
    "            preds = exp_preds / np.sum(exp_preds)\n",
    "            probas = np.random.multinomial(1, preds, 1)\n",
    "            next_index =  np.argmax(probas)\n",
    "\n",
    "\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://vignette.wikia.nocookie.net/looneytunes/images/e/e1/All.jpg/revision/latest/scale-to-width-down/260?cb=20150313020828)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
